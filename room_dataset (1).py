# -*- coding: utf-8 -*-
"""room_dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fPmIxiNuiKnBCL9PQMcKLjYL84-joQ10
"""

import pandas as pd

import numpy as np

import os

import cv2

from sklearn.preprocessing import LabelEncoder

from sklearn.model_selection import train_test_split

from tensorflow.keras import layers

df=os.listdir('/content/drive/MyDrive/rooms_dataset')

df

images=[]
labels=[]
im_size=100
for room in df:
  room_path=os.path.join('/content/drive/MyDrive/rooms_dataset',room)
  for  file in os.listdir(room_path):
    img=cv2.imread(os.path.join(room_path,file))
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)#convert image in rgb form
    img=cv2.resize(img,(im_size,im_size))#resize the image
    images.append(img)
    labels.append(room)

images=np.array(images,dtype='float32')/255.0
#convert each images into numpy array and normalize

images

labels=np.array(labels)

print(f'Images shape{images.shape}')
print(f'Labels shape{labels.shape}')

print(f'Example label:',labels[300])

le=LabelEncoder()

y_encoded=le.fit_transform(labels)

y_encoded

train_x, test_x, train_y, test_y = train_test_split(images, y_encoded, test_size=0.1, random_state=42, stratify=y_encoded
)

train_x.shape

train_x = train_x.reshape(train_x.shape[0], -1)
test_x = test_x.reshape(test_x.shape[0], -1)
print("Flattened input shape:", train_x.shape)

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow import keras

# ----- ðŸ§© DATA AUGMENTATION -----
datagen = ImageDataGenerator(
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    zoom_range=0.15,
    horizontal_flip=True,
    brightness_range=[0.8, 1.2],
    fill_mode='nearest'
)

# Fit datagen (required if using featurewise_center/std)
# WARNING: ImageDataGenerator expects 4D image data (samples, height, width, channels).
# The 'train_x' variable is currently flattened to (samples, features).
# Running datagen.fit(train_x) with flattened data will likely result in a ValueError or incorrect augmentation.
# If you intend to use data augmentation, it should be applied to the original unflattened images
# (e.g., 'images' before flattening) and then these augmented images would be flattened for MLP input,
# or you should consider using a Convolutional Neural Network (CNN) architecture.
# datagen.fit(train_x) # This line will likely cause an error due to incorrect input shape.

# Flatten data for MLP
# train_x and test_x are already flattened from previous steps, so these lines are redundant.
input_dim = train_x.shape[1]
num_classes = len(df) # Corrected from 'room_types', which was not defined

# ----- ðŸ§  MLP MODEL -----
model = keras.Sequential([
    layers.Dense(512, activation='relu', input_shape=(input_dim,)),
    layers.BatchNormalization(),
    layers.Dropout(0.4),
    layers.Dense(256, activation='relu'),
    layers.BatchNormalization(),
    layers.Dropout(0.4),
    layers.Dense(128, activation='relu'),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(
    optimizer=keras.optimizers.Adam(learning_rate=0.001),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print(datagen)

# ----- TRAIN WITH AUGMENTATION -----
# Keras .fit() canâ€™t directly augment flattened data, so we do it manually in batches

# First, split the original unflattened images for augmentation
# This ensures we have the original 4D shape for ImageDataGenerator
X_train_aug, X_test_aug, y_train_aug, y_test_aug = train_test_split(images, y_encoded, test_size=0.1, random_state=42, stratify=y_encoded)

def augmented_batches(x_unflat, y_labels, batch_size):
    """Generator that yields flattened augmented images"""
    # Use datagen.flow with the unflattened images
    for batch_x_unflat, batch_y in datagen.flow(x_unflat, y_labels, batch_size=batch_size, shuffle=True):
        # Flatten the augmented batch before yielding
        batch_x_flat = batch_x_unflat.reshape(batch_x_unflat.shape[0], -1)
        yield batch_x_flat, batch_y

steps_per_epoch = len(X_train_aug) // 16 # Use the length of the unflattened training set

history = model.fit(
    # Pass the unflattened training data (X_train_aug) to the generator
    augmented_batches(X_train_aug, y_train_aug, 16),
    steps_per_epoch=steps_per_epoch,
    epochs=50,
    # Use the existing flattened test data for validation
    validation_data=(test_x, test_y), # test_x is already flattened, test_y is already encoded
    verbose=1
)

# ----- EVALUATION -----
# Use the existing flattened test data for final evaluation
test_loss, test_acc = model.evaluate(test_x, test_y, verbose=0)
print(f"\nâœ… Test Accuracy: {test_acc:.3f}")

import matplotlib.pyplot as plt

h = history.history
plt.figure(figsize=(12,4))
plt.subplot(1,2,1)
plt.plot(h['loss'], label='train loss'); plt.plot(h['val_loss'], label='val loss'); plt.legend()
plt.title('Loss')
plt.subplot(1,2,2)
plt.plot(h['accuracy'], label='train acc'); plt.plot(h['val_accuracy'], label='val acc'); plt.legend()
plt.title('Accuracy')
plt.show()

from tensorflow.keras.preprocessing.image import load_img, img_to_array
img_path = '/content/rooooooom.jpeg'
img = load_img(img_path, target_size=(im_size, im_size))
img = img_to_array(img) / 255.0
img = img.reshape((1, -1)) # flatten for MLP
yhat = model.predict(img)
pred_class = np.argmax(yhat)
pred_label = le.inverse_transform([pred_class])[0]
print("\nPredicted class:", pred_label)

